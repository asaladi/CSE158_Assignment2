{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0012bb84",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b007814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a39f5d6",
   "metadata": {},
   "source": [
    "# Loader Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d6052f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    # Open in text mode ('rt') with UTF-8 encoding for JSON lines\n",
    "    path = \"datasets/\" + path\n",
    "    with gzip.open(path, 'rt', encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            # Safely parse each line as JSON\n",
    "            yield json.loads(l)\n",
    "\n",
    "def load_to_dict(file_to_read):\n",
    "    data = []\n",
    "    try:\n",
    "        for item in readGz(file_to_read):\n",
    "            data.append(item)\n",
    "    except EOFError as e:\n",
    "        # Catching the specific EOFError indicating a corrupted file\n",
    "        print(f\"EOFError: Compressed file '{file_to_read}' ended prematurely. Error: {e}\")\n",
    "        print(f\"This often indicates a corrupted or incomplete gzip file. Successfully loaded {len(data)} items before the error.\")\n",
    "    except Exception as e:\n",
    "        # Catching other potential errors during decompression or JSON parsing\n",
    "        print(f\"An unexpected error occurred while reading '{file_to_read}': {e}\")\n",
    "        print(f\"Successfully loaded {len(data)} items before the error.\")\n",
    "    return data\n",
    "\n",
    "def save_likes(filename, data_dict):\n",
    "    filename = \"eval/\"+filename\n",
    "    with open(filename, \"w\") as fp:\n",
    "        json.dump(data_dict, fp, indent=4)\n",
    "    print(\"Saved to \", filename)\n",
    "\n",
    "def load_user_likes(filename):\n",
    "    \"\"\"\n",
    "    Load a user_likes JSON file back into a dict[user_id] = list of liked places.\n",
    "    \"\"\"\n",
    "    filename = \"eval/\"+filename\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Ensure values are lists, not sets or other types\n",
    "    return {user_id: list(likes) for user_id, likes in data.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bceff4e",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58453888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c84cab03",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845f375",
   "metadata": {},
   "source": [
    "## Universal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "41b1a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 30\n",
    "RANDOM_SEED = 42\n",
    "POS_THRESHOLD = 4\n",
    "\n",
    "RATIO_FOR_REVEALED = 0.8\n",
    "\n",
    "# Files we're checking the evaluation from\n",
    "REVIEW_DATA_FNAME = \"review-Oregon_10.json.gz\"\n",
    "METADATA_DATA_FNAME = \"meta-Oregon.json.gz\"\n",
    "\n",
    "FULL_LIKES_DATA_FNAME = \"users_likes_full.json\"\n",
    "REVEALED_LIKES_DATA_FNAME = \"users_revealed_likes.json\"\n",
    "HIDDEN_LIKES_DATA_FNAME = \"users_hidden_likes.json\"\n",
    "HIDDEN_LIKES_BPR_DATA_FNAME = \"users_hidden_likes_BPR.json\"\n",
    "\n",
    "ITER_UPDATE_REC_FNAME = \"iterative_update_recommendation_per_user.json\"\n",
    "BPR_REC_FNAME = \"bpr_recommendation_per_user.json\"\n",
    "\n",
    "BASELINE_REC_FNAME = \"baseline_recommendation_per_user.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc539fd",
   "metadata": {},
   "source": [
    "## The Pre-processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0b5ceb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "reviews = load_to_dict(REVIEW_DATA_FNAME)[:100000]\n",
    "metadata = load_to_dict(METADATA_DATA_FNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3ed1c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dupes:  1477\n",
      "Num dupes removed:  0\n",
      "Saved to  eval/users_likes_full.json\n",
      "Saved to  eval/users_revealed_likes.json\n",
      "Saved to  eval/users_hidden_likes.json\n"
     ]
    }
   ],
   "source": [
    "# Get each users' highly reviewed stores list\n",
    "# users_likes[user_id] = [stores they rated >= 4]\n",
    "users_likes = defaultdict(set)\n",
    "dupe_review_count = 0\n",
    "dupe_removed_count = 0\n",
    "\n",
    "for review in reviews:\n",
    "    user_id = review[\"user_id\"]\n",
    "    gmap_id = review[\"gmap_id\"]\n",
    "    rating = review[\"rating\"]\n",
    "\n",
    "    if gmap_id in users_likes[user_id]:\n",
    "        dupe_review_count += 1\n",
    "    \n",
    "    # Use the most recent review, meaning if a user re-reviewed a place and they didn't like it, update our set\n",
    "    if gmap_id in users_likes[user_id] and rating < 4:\n",
    "        users_likes[user_id].remove(gmap_id)\n",
    "        dupe_removed_count += 1\n",
    "\n",
    "    if rating >= POS_THRESHOLD and (gmap_id not in users_likes[user_id]):\n",
    "        users_likes[user_id].add(gmap_id)\n",
    "\n",
    "print(\"Num dupes: \", dupe_review_count) \n",
    "print(\"Num dupes removed: \", dupe_removed_count) \n",
    "\n",
    "# Split off the users_likes to revealed and hidden\n",
    "users_revealed_likes = defaultdict(list)\n",
    "users_hidden_likes = defaultdict(list)\n",
    "users_total_likes = defaultdict(list)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "for user_id, liked_places in users_likes.items():\n",
    "    # For now let's say 8:2 ratio for revealed vs hidden\n",
    "    # Shuffle before splitting\n",
    "\n",
    "    liked_list = list(liked_places)\n",
    "    num_likes = len(liked_list)\n",
    "    \n",
    "    random.shuffle(liked_list)\n",
    "\n",
    "    # ensures at least 1 review is hidden\n",
    "    min_hidden_count = 1\n",
    "    split_point = max(min_hidden_count, int(RATIO_FOR_REVEALED * num_likes))\n",
    "\n",
    "    revealed = liked_list[split_point:]\n",
    "    hidden = liked_list[:split_point]\n",
    "    \n",
    "    if len(hidden) >= min_hidden_count:\n",
    "        users_revealed_likes[user_id] = revealed\n",
    "        users_hidden_likes[user_id] = hidden\n",
    "        users_total_likes[user_id] = liked_list\n",
    "\n",
    "# Save user likes: revealed, hidden, and full\n",
    "save_likes(FULL_LIKES_DATA_FNAME, users_total_likes)\n",
    "save_likes(REVEALED_LIKES_DATA_FNAME, users_revealed_likes)\n",
    "save_likes(HIDDEN_LIKES_DATA_FNAME, users_hidden_likes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a324955",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96422e93",
   "metadata": {},
   "source": [
    "## Iterative Update (HW3) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7803b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The functions we'll use for to update in the iterations\n",
    "\n",
    "def getGlobalAverage(trainRatings):\n",
    "    # Return the average rating in the training set\n",
    "    res = numpy.average(trainRatings)\n",
    "\n",
    "    return res\n",
    "\n",
    "def alphaUpdate(ratingsTrain, alpha, betaU, betaLoc, lamb):\n",
    "    # Update equation for alpha\n",
    "    newAlpha = 0\n",
    "\n",
    "    # From slide 83 of the recommendation slide\n",
    "    # alpha = sum_{u,i in train} (R_u,i - (betaU + betaLoc)) / Ntrain\n",
    "    Ntrain = len(ratingsTrain)\n",
    "\n",
    "    for u, loc, rating in ratingsTrain:\n",
    "        # u, loc, rating = r[\"user_id\"], r[\"gmap_id\"], r[\"rating\"]\n",
    "\n",
    "        newAlpha += rating - (betaU[u] + betaLoc[loc])\n",
    "    \n",
    "    newAlpha /= Ntrain\n",
    "\n",
    "    return newAlpha\n",
    "\n",
    "def betaUUpdate(ratingsPerUser, alpha, betaU, betaLoc, lamb):\n",
    "    # Update equation for betaU\n",
    "    newBetaU = {}\n",
    "\n",
    "    # From slide 83 of the recommendation slide\n",
    "    # betaU = sum_{i in I_u} (R_u,i - (alpha + betaLoc)) / (lamb + |I_u|)\n",
    "    \n",
    "    # Structure is ratingsPerUser[user] = [(location, rating)]\n",
    "    # betaU[user] = how much does this user tend to rate things above mean\n",
    "\n",
    "    for u in ratingsPerUser:\n",
    "        curr = 0\n",
    "        \n",
    "        for i, r in ratingsPerUser[u]:\n",
    "            curr += r - (alpha + betaLoc[i])\n",
    "    \n",
    "        curr /= (lamb + len(ratingsPerUser[u]))\n",
    "\n",
    "        newBetaU[u] = curr\n",
    "\n",
    "    return newBetaU\n",
    "\n",
    "def betaLocUpdate(ratingsPerLocation, alpha, betaU, betaLoc, lamb):\n",
    "    # Update equation for betaLoc\n",
    "    newBetaLoc = {}\n",
    "\n",
    "    # From slide 83 of the recommendation slide\n",
    "    # betaU = sum_{u in U_i} (R_u,i - (alpha + betaU)) / (lamb + |U_i|)\n",
    "\n",
    "    # ratingsPerLocation[location] = [(user, rating)]\n",
    "\n",
    "    for i in ratingsPerLocation:\n",
    "        curr = 0\n",
    "\n",
    "        for u, r in ratingsPerLocation[i]:\n",
    "            curr += r - (alpha + betaU[u])\n",
    "        \n",
    "        curr /= (lamb + len(ratingsPerLocation[i]))\n",
    "\n",
    "        newBetaLoc[i] = curr\n",
    "\n",
    "    return newBetaLoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6e10282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model we're using\n",
    "def iterativeUpdateModel(ratingsTrain, ratingsPerUser, ratingsPerLocation, alpha, betaU, betaLoc):\n",
    "    # Improve upon your model from the previous question (e.g. by running multiple iterations)\n",
    "\n",
    "    # Running multiple iterations\n",
    "    lamb = 0.5\n",
    "    for i in range(100):\n",
    "        alpha = alphaUpdate(ratingsTrain, alpha, betaU, betaLoc, lamb)\n",
    "        betaU = betaUUpdate(ratingsPerUser, alpha, betaU, betaLoc, lamb)\n",
    "        betaLoc = betaLocUpdate(ratingsPerLocation, alpha, betaU, betaLoc, lamb)\n",
    "\n",
    "    return alpha, betaU, betaLoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "81f243b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra pre-processing for this specific model: get all users and locations from the test set\n",
    "# Also, get all the reviews that are revealed / negative (which will be used to train)\n",
    "\n",
    "test_users_IUM = set()\n",
    "test_locations_IUM = set()\n",
    "\n",
    "# of (user_id, gmap_id, rating)\n",
    "test_revealed_and_negative_reviews = set()\n",
    "\n",
    "for review in reviews:\n",
    "    user = review[\"user_id\"]\n",
    "    test_users_IUM.add(user)\n",
    "\n",
    "    loc = review[\"gmap_id\"]\n",
    "    test_locations_IUM.add(loc)\n",
    "\n",
    "    rating = review[\"rating\"]\n",
    "\n",
    "    if loc in users_revealed_likes[user] or rating < 4:\n",
    "        test_revealed_and_negative_reviews.add((user, loc, rating))\n",
    "\n",
    "test_users_IUM = list(test_users_IUM)\n",
    "test_locations_IUM = list(test_locations_IUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3614ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the train set to figure out the generally ideal alpha, betaU, betaLoc of the model in this kind of task\n",
    "ratingsTrain = test_revealed_and_negative_reviews\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerLocation = defaultdict(list)\n",
    "for u, loc, r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((loc,r))\n",
    "    ratingsPerLocation[loc].append((u,r))\n",
    "\n",
    "trainRatings = [r for _, _, r in ratingsTrain]\n",
    "\n",
    "betaU = {}\n",
    "betaLoc = {}\n",
    "for u in ratingsPerUser:\n",
    "    betaU[u] = 0\n",
    "\n",
    "for loc in ratingsPerLocation:\n",
    "    betaLoc[loc] = 0\n",
    "\n",
    "alpha = getGlobalAverage(trainRatings) # Could initialize anywhere, this is a guess\n",
    "\n",
    "alpha, betaU, betaLoc = iterativeUpdateModel(ratingsTrain, ratingsPerUser, ratingsPerLocation, alpha, betaU, betaLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "82ff8fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65671/65671 [01:22<00:00, 797.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to  eval/iterative_update_recommendation_per_user.json\n"
     ]
    }
   ],
   "source": [
    "# Go through each user and location, get the recommendations\n",
    "recommendation = {}\n",
    "\n",
    "for user_id in tqdm(test_users_IUM):\n",
    "    # min-heap storing (score, gmap_id)\n",
    "    heap = []\n",
    "\n",
    "    bu = betaU.get(user_id, 0)\n",
    "\n",
    "    revealed = users_revealed_likes[user_id]\n",
    "\n",
    "    for gmap_id in test_locations_IUM:\n",
    "\n",
    "        if gmap_id in revealed:\n",
    "            continue\n",
    "\n",
    "        bi = betaLoc.get(gmap_id, 0)\n",
    "        score = alpha + bu + bi\n",
    "\n",
    "        if len(heap) < TOP_K:\n",
    "            # just push until full\n",
    "            heapq.heappush(heap, (score, gmap_id))\n",
    "        else:\n",
    "            # if better than the smallest in heap → replace the smallest\n",
    "            if score > heap[0][0]:\n",
    "                heapq.heapreplace(heap, (score, gmap_id))\n",
    "\n",
    "    # extract best K sorted from highest to lowest\n",
    "    heap.sort(reverse=True)\n",
    "    recommendation[user_id] = [gmap_id for score, gmap_id in heap]\n",
    "\n",
    "# Export to json\n",
    "save_likes(ITER_UPDATE_REC_FNAME, recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e78a398",
   "metadata": {},
   "source": [
    "## Bayesian Personalized Ranking (BPR) Model\n",
    "Note: Codes referenced from the Professor's page Chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8a90e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPR-specific variables\n",
    "MIN_INTERACTIONS_PER_USER = 1\n",
    "MAX_USERS = 100000\n",
    "MAX_ITEMS = 100000\n",
    "\n",
    "LATENT_DIM = 64\n",
    "LEARNING_RATE = 0.01\n",
    "REG_LAMBDA = 1e-5\n",
    "NSAMPLES_PER_BATCH = 50000\n",
    "N_TRAIN_STEPS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "05d1d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra pre-processing for this model\n",
    "random.seed(RANDOM_SEED)\n",
    "numpy.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "df = pd.DataFrame(reviews)\n",
    "\n",
    "\n",
    "df_pos = df[df[\"rating\"] >= POS_THRESHOLD].copy()\n",
    "\n",
    "user_counts = df_pos[\"user_id\"].value_counts()\n",
    "eligible_users = user_counts[user_counts >= MIN_INTERACTIONS_PER_USER].index\n",
    "\n",
    "df_pos = df_pos[df_pos[\"user_id\"].isin(eligible_users)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Limiting the unique users and items. This is done for the sake of time.\n",
    "# For the record, we tried running this without the limitation and the score we got was negligibly similar to the one with this limitation.\n",
    "unique_users = df_pos[\"user_id\"].unique()\n",
    "if MAX_USERS is not None:\n",
    "    unique_users = unique_users[:MAX_USERS]\n",
    "\n",
    "df_pos = df_pos[df_pos[\"user_id\"].isin(unique_users)]\n",
    "\n",
    "unique_items = df_pos[\"gmap_id\"].unique()\n",
    "if MAX_ITEMS is not None:\n",
    "    unique_items = unique_items[:MAX_ITEMS]\n",
    "\n",
    "df_pos = df_pos[df_pos[\"gmap_id\"].isin(unique_items)].reset_index(drop=True)\n",
    "\n",
    "user_id_to_idx = {u: idx for idx, u in enumerate(unique_users)}\n",
    "item_id_to_idx = {i: idx for idx, i in enumerate(unique_items)}\n",
    "\n",
    "df_pos[\"user_idx\"] = df_pos[\"user_id\"].map(user_id_to_idx)\n",
    "df_pos[\"item_idx\"] = df_pos[\"gmap_id\"].map(item_id_to_idx)\n",
    "\n",
    "num_users = len(user_id_to_idx)\n",
    "num_items = len(item_id_to_idx)\n",
    "\n",
    "\n",
    "# Shuffle rows (if no timestamp, just randomize)\n",
    "if \"time\" in df_pos.columns:\n",
    "    df_pos = df_pos.sort_values([\"user_idx\", \"time\"])\n",
    "else:\n",
    "    df_pos = df_pos.sample(frac=1.0, random_state=RANDOM_SEED)\n",
    "\n",
    "train_rows = []\n",
    "test_rows = []\n",
    "\n",
    "# Split each user's interactions 80:20\n",
    "for user_id, group in df_pos.groupby(\"user_id\"):\n",
    "    idx_list = group.index.tolist()\n",
    "    random.shuffle(idx_list)\n",
    "    \n",
    "    split_point = max(1, int(RATIO_FOR_REVEALED * len(idx_list)))  # ensure at least 1 row in train\n",
    "    train_rows.extend(idx_list[:split_point])\n",
    "    test_rows.extend(idx_list[split_point:])\n",
    "\n",
    "train_df = df_pos.loc[train_rows].reset_index(drop=True)\n",
    "test_df = df_pos.loc[test_rows].reset_index(drop=True)\n",
    "\n",
    "# Get a translation dictionary so we know the user and location id we're referring to by their idx after the fitting\n",
    "idx_to_user_id = {idx: u for u, idx in user_id_to_idx.items()}\n",
    "idx_to_item_id = {idx: i for i, idx in item_id_to_idx.items()}\n",
    "\n",
    "\n",
    "interactions_train = list(\n",
    "    zip(\n",
    "        train_df[\"user_idx\"].astype(int).tolist(),\n",
    "        train_df[\"item_idx\"].astype(int).tolist(),\n",
    "        train_df[\"rating\"].tolist()\n",
    "    )\n",
    ")\n",
    "\n",
    "items_per_user_train = defaultdict(set)\n",
    "for u, i, r in interactions_train:\n",
    "    items_per_user_train[u].add(i)\n",
    "\n",
    "all_items = list(range(num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "400d5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model we're using\n",
    "class BPRbatch(tf.keras.Model):\n",
    "    def __init__(self, K, lamb):\n",
    "        super().__init__()\n",
    "        self.lamb = lamb\n",
    "\n",
    "        # Global item bias\n",
    "        self.betaI = self.add_weight(\n",
    "            name=\"betaI\",\n",
    "            shape=(num_items,),\n",
    "            initializer=tf.random_normal_initializer(stddev=0.001),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        # User latent factors\n",
    "        self.gammaU = self.add_weight(\n",
    "            name=\"gammaU\",\n",
    "            shape=(num_users, K),\n",
    "            initializer=tf.random_normal_initializer(stddev=0.001),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        # Item latent factors\n",
    "        self.gammaI = self.add_weight(\n",
    "            name=\"gammaI\",\n",
    "            shape=(num_items, K),\n",
    "            initializer=tf.random_normal_initializer(stddev=0.001),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def score(self, sampleU, sampleI):\n",
    "        # sampleU, sampleI are index tensors\n",
    "        u = tf.cast(sampleU, tf.int32)\n",
    "        i = tf.cast(sampleI, tf.int32)\n",
    "\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "\n",
    "        x_ui = beta_i + tf.reduce_sum(gamma_u * gamma_i, axis=1)\n",
    "        return x_ui\n",
    "\n",
    "    def call(self, sampleU, sampleI, sampleJ):\n",
    "        x_ui = self.score(sampleU, sampleI)\n",
    "        x_uj = self.score(sampleU, sampleJ)\n",
    "        # BPR loss: -log σ(x_ui - x_uj)\n",
    "        loss = -tf.reduce_mean(tf.math.log_sigmoid(x_ui - x_uj))\n",
    "        return loss\n",
    "\n",
    "    def reg(self):\n",
    "        return self.lamb * (\n",
    "            tf.nn.l2_loss(self.betaI)\n",
    "            + tf.nn.l2_loss(self.gammaU)\n",
    "            + tf.nn.l2_loss(self.gammaI)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3be740b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One mini-batch objective: 0.6932\n",
      "Step 5, objective = 0.6851\n",
      "Step 10, objective = 0.6778\n",
      "Step 15, objective = 0.6705\n",
      "Step 20, objective = 0.6644\n",
      "Step 25, objective = 0.6569\n",
      "Step 30, objective = 0.6494\n",
      "Step 35, objective = 0.6360\n",
      "Step 40, objective = 0.6144\n",
      "Step 45, objective = 0.5855\n",
      "Step 50, objective = 0.5536\n",
      "Step 55, objective = 0.5217\n",
      "Step 60, objective = 0.4951\n",
      "Step 65, objective = 0.4743\n",
      "Step 70, objective = 0.4634\n",
      "Step 75, objective = 0.4572\n",
      "Step 80, objective = 0.4539\n",
      "Step 85, objective = 0.4533\n",
      "Step 90, objective = 0.4502\n",
      "Step 95, objective = 0.4508\n",
      "Step 100, objective = 0.4492\n",
      "Step 105, objective = 0.4481\n",
      "Step 110, objective = 0.4489\n",
      "Step 115, objective = 0.4483\n",
      "Step 120, objective = 0.4482\n",
      "Step 125, objective = 0.4477\n",
      "Step 130, objective = 0.4471\n",
      "Step 135, objective = 0.4482\n",
      "Step 140, objective = 0.4469\n",
      "Step 145, objective = 0.4478\n",
      "Step 150, objective = 0.4470\n",
      "Step 155, objective = 0.4473\n",
      "Step 160, objective = 0.4471\n",
      "Step 165, objective = 0.4465\n",
      "Step 170, objective = 0.4469\n",
      "Step 175, objective = 0.4468\n",
      "Step 180, objective = 0.4462\n",
      "Step 185, objective = 0.4468\n",
      "Step 190, objective = 0.4457\n",
      "Step 195, objective = 0.4458\n",
      "Step 200, objective = 0.4467\n",
      "Step 205, objective = 0.4461\n",
      "Step 210, objective = 0.4459\n",
      "Step 215, objective = 0.4456\n",
      "Step 220, objective = 0.4456\n",
      "Step 225, objective = 0.4461\n",
      "Step 230, objective = 0.4454\n",
      "Step 235, objective = 0.4455\n",
      "Step 240, objective = 0.4447\n",
      "Step 245, objective = 0.4449\n",
      "Step 250, objective = 0.4448\n",
      "Step 255, objective = 0.4457\n",
      "Step 260, objective = 0.4445\n",
      "Step 265, objective = 0.4443\n",
      "Step 270, objective = 0.4442\n",
      "Step 275, objective = 0.4448\n",
      "Step 280, objective = 0.4438\n",
      "Step 285, objective = 0.4443\n",
      "Step 290, objective = 0.4443\n",
      "Step 295, objective = 0.4444\n",
      "Step 300, objective = 0.4436\n",
      "Step 305, objective = 0.4446\n",
      "Step 310, objective = 0.4443\n",
      "Step 315, objective = 0.4439\n",
      "Step 320, objective = 0.4447\n",
      "Step 325, objective = 0.4450\n",
      "Step 330, objective = 0.4445\n",
      "Step 335, objective = 0.4444\n",
      "Step 340, objective = 0.4437\n",
      "Step 345, objective = 0.4439\n",
      "Step 350, objective = 0.4445\n",
      "Step 355, objective = 0.4444\n",
      "Step 360, objective = 0.4442\n",
      "Step 365, objective = 0.4434\n",
      "Step 370, objective = 0.4442\n",
      "Step 375, objective = 0.4440\n",
      "Step 380, objective = 0.4441\n",
      "Step 385, objective = 0.4433\n",
      "Step 390, objective = 0.4438\n",
      "Step 395, objective = 0.4442\n",
      "Step 400, objective = 0.4441\n",
      "Step 405, objective = 0.4440\n",
      "Step 410, objective = 0.4442\n",
      "Step 415, objective = 0.4435\n",
      "Step 420, objective = 0.4444\n",
      "Step 425, objective = 0.4446\n",
      "Step 430, objective = 0.4441\n",
      "Step 435, objective = 0.4435\n",
      "Step 440, objective = 0.4429\n",
      "Step 445, objective = 0.4436\n",
      "Step 450, objective = 0.4438\n",
      "Step 455, objective = 0.4438\n",
      "Step 460, objective = 0.4441\n",
      "Step 465, objective = 0.4436\n",
      "Step 470, objective = 0.4431\n",
      "Step 475, objective = 0.4436\n",
      "Step 480, objective = 0.4428\n",
      "Step 485, objective = 0.4441\n",
      "Step 490, objective = 0.4441\n",
      "Step 495, objective = 0.4431\n",
      "Step 500, objective = 0.4434\n",
      "Step 505, objective = 0.4439\n",
      "Step 510, objective = 0.4426\n",
      "Step 515, objective = 0.4433\n",
      "Step 520, objective = 0.4438\n",
      "Step 525, objective = 0.4429\n",
      "Step 530, objective = 0.4440\n",
      "Step 535, objective = 0.4433\n",
      "Step 540, objective = 0.4431\n",
      "Step 545, objective = 0.4437\n",
      "Step 550, objective = 0.4436\n",
      "Step 555, objective = 0.4430\n",
      "Step 560, objective = 0.4434\n",
      "Step 565, objective = 0.4429\n",
      "Step 570, objective = 0.4422\n",
      "Step 575, objective = 0.4435\n",
      "Step 580, objective = 0.4434\n",
      "Step 585, objective = 0.4433\n",
      "Step 590, objective = 0.4442\n",
      "Step 595, objective = 0.4433\n",
      "Step 600, objective = 0.4435\n",
      "Step 605, objective = 0.4439\n",
      "Step 610, objective = 0.4428\n",
      "Step 615, objective = 0.4438\n",
      "Step 620, objective = 0.4443\n",
      "Step 625, objective = 0.4426\n",
      "Step 630, objective = 0.4426\n",
      "Step 635, objective = 0.4438\n",
      "Step 640, objective = 0.4431\n",
      "Step 645, objective = 0.4431\n",
      "Step 650, objective = 0.4427\n",
      "Step 655, objective = 0.4427\n",
      "Step 660, objective = 0.4440\n",
      "Step 665, objective = 0.4430\n",
      "Step 670, objective = 0.4432\n",
      "Step 675, objective = 0.4426\n",
      "Step 680, objective = 0.4435\n",
      "Step 685, objective = 0.4434\n",
      "Step 690, objective = 0.4429\n",
      "Step 695, objective = 0.4430\n",
      "Step 700, objective = 0.4423\n",
      "Step 705, objective = 0.4434\n",
      "Step 710, objective = 0.4430\n",
      "Step 715, objective = 0.4427\n",
      "Step 720, objective = 0.4429\n",
      "Step 725, objective = 0.4438\n",
      "Step 730, objective = 0.4425\n",
      "Step 735, objective = 0.4431\n",
      "Step 740, objective = 0.4433\n",
      "Step 745, objective = 0.4425\n",
      "Step 750, objective = 0.4427\n",
      "Step 755, objective = 0.4421\n",
      "Step 760, objective = 0.4431\n",
      "Step 765, objective = 0.4420\n",
      "Step 770, objective = 0.4428\n",
      "Step 775, objective = 0.4428\n",
      "Step 780, objective = 0.4430\n",
      "Step 785, objective = 0.4424\n",
      "Step 790, objective = 0.4420\n",
      "Step 795, objective = 0.4423\n",
      "Step 800, objective = 0.4432\n",
      "Step 805, objective = 0.4420\n",
      "Step 810, objective = 0.4417\n",
      "Step 815, objective = 0.4425\n",
      "Step 820, objective = 0.4431\n",
      "Step 825, objective = 0.4425\n",
      "Step 830, objective = 0.4430\n",
      "Step 835, objective = 0.4422\n",
      "Step 840, objective = 0.4424\n",
      "Step 845, objective = 0.4425\n",
      "Step 850, objective = 0.4431\n",
      "Step 855, objective = 0.4427\n",
      "Step 860, objective = 0.4418\n",
      "Step 865, objective = 0.4432\n",
      "Step 870, objective = 0.4433\n",
      "Step 875, objective = 0.4421\n",
      "Step 880, objective = 0.4419\n",
      "Step 885, objective = 0.4424\n",
      "Step 890, objective = 0.4423\n",
      "Step 895, objective = 0.4427\n",
      "Step 900, objective = 0.4426\n",
      "Step 905, objective = 0.4424\n",
      "Step 910, objective = 0.4425\n",
      "Step 915, objective = 0.4419\n",
      "Step 920, objective = 0.4418\n",
      "Step 925, objective = 0.4424\n",
      "Step 930, objective = 0.4427\n",
      "Step 935, objective = 0.4421\n",
      "Step 940, objective = 0.4428\n",
      "Step 945, objective = 0.4430\n",
      "Step 950, objective = 0.4434\n",
      "Step 955, objective = 0.4431\n",
      "Step 960, objective = 0.4422\n",
      "Step 965, objective = 0.4416\n",
      "Step 970, objective = 0.4426\n",
      "Step 975, objective = 0.4429\n",
      "Step 980, objective = 0.4422\n",
      "Step 985, objective = 0.4433\n",
      "Step 990, objective = 0.4422\n",
      "Step 995, objective = 0.4426\n",
      "Step 1000, objective = 0.4418\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "modelBPR = BPRbatch(LATENT_DIM, REG_LAMBDA)\n",
    "\n",
    "def trainingStepBPR(model, interactions, items_per_user, items, Nsamples):\n",
    "    sampleU, sampleI, sampleJ = [], [], []\n",
    "\n",
    "    for _ in range(Nsamples):\n",
    "        u, i, r = random.choice(interactions)\n",
    "        j = random.choice(items)\n",
    "        while j in items_per_user[u]:\n",
    "            j = random.choice(items)\n",
    "\n",
    "        sampleU.append(u)\n",
    "        sampleI.append(i)\n",
    "        sampleJ.append(j)\n",
    "\n",
    "    # Convert lists → tensors\n",
    "    sampleU_tf = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "    sampleI_tf = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "    sampleJ_tf = tf.convert_to_tensor(sampleJ, dtype=tf.int32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = model(sampleU_tf, sampleI_tf, sampleJ_tf)\n",
    "        loss += model.reg()\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # Pair gradients with variables, skipping any None grads just in case\n",
    "    grads_and_vars = [\n",
    "        (g, v) for g, v in zip(grads, model.trainable_variables) if g is not None\n",
    "    ]\n",
    "\n",
    "    if grads_and_vars:\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "    else:\n",
    "        print(\"Warning: no gradients to apply this step.\")\n",
    "\n",
    "    return float(loss.numpy())\n",
    "\n",
    "# Run the training\n",
    "test_loss = trainingStepBPR(\n",
    "    modelBPR,\n",
    "    interactions_train,\n",
    "    items_per_user_train,\n",
    "    all_items,\n",
    "    Nsamples=NSAMPLES_PER_BATCH  # mini testing\n",
    ")\n",
    "\n",
    "print(f\"One mini-batch objective: {test_loss:.4f}\")\n",
    "\n",
    "for step in range(N_TRAIN_STEPS):\n",
    "    obj = trainingStepBPR(\n",
    "        modelBPR,\n",
    "        interactions_train,\n",
    "        items_per_user_train,\n",
    "        all_items,\n",
    "        NSAMPLES_PER_BATCH,\n",
    "    )\n",
    "    if (step + 1) % 5 == 0:\n",
    "        print(f\"Step {step + 1}, objective = {obj:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "87a0154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the recommendation\n",
    "\n",
    "test_items_per_user = defaultdict(list)\n",
    "for _, row in test_df.iterrows():\n",
    "    u = int(row[\"user_idx\"])\n",
    "    i = int(row[\"item_idx\"])\n",
    "    test_items_per_user[u].append(i)\n",
    "\n",
    "def get_top_k_recommendations(model, train_items_per_user, test_items_per_user, items, k, idx_to_user_id, idx_to_item_id):\n",
    "    \"\"\"\n",
    "    Returns: dict of user_id -> list of top-k gmap_ids, excluding training items.\n",
    "    \"\"\"\n",
    "    recs = {}\n",
    "    users = list(test_items_per_user.keys())\n",
    "    all_items_array = numpy.array(items, dtype=numpy.int32)\n",
    "\n",
    "    for idx, u in enumerate(users):\n",
    "        user_id = idx_to_user_id[u]\n",
    "\n",
    "        train_items = train_items_per_user[u]\n",
    "\n",
    "        # Candidate items = all items not already interacted with\n",
    "        candidate_mask = ~numpy.isin(all_items_array, list(train_items))\n",
    "        candidate_items = all_items_array[candidate_mask]\n",
    "\n",
    "        if len(candidate_items) == 0:\n",
    "            recs[user_id] = []\n",
    "            continue\n",
    "\n",
    "        # Score all candidate items\n",
    "        u_list = numpy.full(len(candidate_items), u, dtype=numpy.int32)\n",
    "        scores = model.score(u_list, candidate_items).numpy()\n",
    "\n",
    "        # Sort scores and get top-k\n",
    "        top_idx = numpy.argsort(-scores)[:k]  # sorted descending\n",
    "        top_item_indices_sorted = candidate_items[top_idx]\n",
    "\n",
    "        # Map indices back to gmap_ids\n",
    "        top_item_ids = [idx_to_item_id[i] for i in top_item_indices_sorted]\n",
    "\n",
    "        recs[user_id] = top_item_ids\n",
    "\n",
    "    return recs\n",
    "\n",
    "# Running the function and getting the recommendations\n",
    "recommendation = get_top_k_recommendations(\n",
    "    modelBPR,\n",
    "    items_per_user_train,\n",
    "    test_items_per_user,\n",
    "    all_items,\n",
    "    TOP_K,\n",
    "    idx_to_user_id,\n",
    "    idx_to_item_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "817645f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to  eval/bpr_recommendation_per_user.json\n",
      "Saved to  eval/users_hidden_likes_BPR.json\n"
     ]
    }
   ],
   "source": [
    "# Exporting to json\n",
    "\n",
    "# Save the recommendations to a file so it can be used in the evaluation function\n",
    "save_likes(BPR_REC_FNAME, recommendation)\n",
    "\n",
    "# Also save the hidden likes\n",
    "users_hidden_likes = defaultdict(list)\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    user_id = idx_to_user_id[row[\"user_idx\"]]\n",
    "    item_id = idx_to_item_id[row[\"item_idx\"]]\n",
    "    users_hidden_likes[user_id].append(item_id)\n",
    "\n",
    "users_hidden_likes = dict(users_hidden_likes)\n",
    "\n",
    "# Saving the hidden likes specific for this\n",
    "# This is because of the 100000 limiting of users and items as done above\n",
    "save_likes(HIDDEN_LIKES_BPR_DATA_FNAME, users_hidden_likes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414a2c8",
   "metadata": {},
   "source": [
    "# Unused Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179129e0",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature vector\n",
    "# def feature(datum):\n",
    "#     feat = [1]\n",
    "\n",
    "#     # The features that make sense to see:\n",
    "#     # price, latitude/longitude, description length, num_of_reviews\n",
    "\n",
    "#     feat.append(len(datum[\"price\"]) if datum[\"price\"] else 0)\n",
    "#     # feat.append(datum[\"latitude\"])\n",
    "#     # feat.append(datum[\"longitude\"])\n",
    "\n",
    "#     feat.append(len(datum[\"description\"]) if datum[\"description\"] else 0)\n",
    "#     feat.append(datum[\"num_of_reviews\"])\n",
    "\n",
    "#     # Days open\n",
    "#     days_open = [0] * 7\n",
    "\n",
    "#     if datum[\"hours\"]:\n",
    "#         for d in datum[\"hours\"]:\n",
    "#             if d[0] == \"Monday\" and str.lower(d[1]) != \"closed\":\n",
    "#                 days_open[0] = 1\n",
    "#             if d[0] == \"Tuesday\" and str.lower(d[1]) != \"closed\":\n",
    "#                 days_open[1] = 1\n",
    "#             if d[0] == \"Wednesday\" and str.lower(d[1]) != \"closed\":\n",
    "#                 days_open[2] = 1\n",
    "#             if d[0] == \"Thursday\" and str.lower(d[1]) != \"closed\":\n",
    "#                 days_open[3] = 1\n",
    "#             if d[0] == \"Friday\" and str.lower(d[1]) != \"closed\":\n",
    "#                 days_open[4] = 1\n",
    "#             if d[0] == \"Saturday\" and str.lower(d[1]) != \"closed\":\n",
    "#                 days_open[5] = 1\n",
    "#             if d[0] == \"Sunday\" and str.lower(d[1]) != \"closed\":\n",
    "#                 days_open[6] = 1\n",
    "\n",
    "#     feat += days_open\n",
    "\n",
    "#     # Categories\n",
    "#     # cat_one_hot = [0] * len(list(cats))\n",
    "    \n",
    "#     # if datum[\"category\"]:\n",
    "#     #     for c in datum[\"category\"]:\n",
    "#     #         cat_one_hot[cats[c]] = 1\n",
    "\n",
    "#     # feat += cat_one_hot\n",
    "\n",
    "#     # Planning\n",
    "#     # plannings_one_hot = [0] * len(list(plannings))\n",
    "#     # if datum[\"MISC\"] and \"Planning\" in datum[\"MISC\"] and datum[\"MISC\"][\"Planning\"]:\n",
    "#     #     for p in datum[\"MISC\"][\"Planning\"]:\n",
    "#     #         plannings_one_hot[plannings[p]] = 1\n",
    "    \n",
    "#     # feat += plannings_one_hot\n",
    "\n",
    "#     # Payment\n",
    "#     # payments_one_hot = [0] * len(list(payments))\n",
    "#     # if datum[\"MISC\"] and \"Payments\" in datum[\"MISC\"] and datum[\"MISC\"][\"Payments\"]:\n",
    "#     #     for p in datum[\"MISC\"][\"Payments\"]:\n",
    "#     #         payments_one_hot[payments[p]] = 1\n",
    "    \n",
    "#     # feat += payments_one_hot\n",
    "\n",
    "#     return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "569677cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Implement and predict\n",
    "\n",
    "# y = numpy.array([d[\"avg_rating\"] for d in train_metadata])\n",
    "\n",
    "# x = numpy.array([feature(d) for d in train_metadata])\n",
    "\n",
    "# # Setting up the logistic regression using sklearn library (class weight is balanced)\n",
    "# regr = linear_model.LinearRegression()\n",
    "\n",
    "# # Train the model using feature = x, label = y\n",
    "# regr.fit(x, y)\n",
    "\n",
    "# # Now predict if we feed the model another feature (x)\n",
    "# x_test = numpy.array([feature(d) for d in metadata])\n",
    "\n",
    "# y_train_prediction = regr.predict(x_test)\n",
    "\n",
    "# loc_and_pred = []\n",
    "\n",
    "# for i in range(len(x_test)):\n",
    "#     loc_and_pred.append((y_train_prediction[i], metadata[i][\"gmap_id\"]))\n",
    "\n",
    "# loc_and_pred.sort(reverse=True)\n",
    "\n",
    "# popularity_list_id = [b for a, b in loc_and_pred]\n",
    "\n",
    "# # Building the dictionary to feed to the evaluation function (same as baseline)\n",
    "# # recommendation[user_id] = [top k items the model recommend]\n",
    "# recommendation = {}\n",
    "\n",
    "# # Get each user that has reviewed\n",
    "# for review in reviews:\n",
    "#     user_id = review[\"user_id\"]\n",
    "\n",
    "#     # Recommend the top number of hidden reviews for each user\n",
    "#     if user_id not in recommendation:\n",
    "#         # Filter the popularity list so that the users' revealed likes isn't included here\n",
    "#         filtered_popularity_list = []\n",
    "\n",
    "#         for name in popularity_list_id:\n",
    "#             if name not in users_revealed_likes[user_id]:\n",
    "#                 filtered_popularity_list.append(name)\n",
    "\n",
    "#             if len(filtered_popularity_list) == k:\n",
    "#                 break\n",
    "\n",
    "#         recommendation[user_id] = filtered_popularity_list[:k]\n",
    "\n",
    "# loader.save_likes(\"linear_regression_recommendation_per_user.json\", recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e7d8d",
   "metadata": {},
   "source": [
    "# Evaluation and Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b42e501",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b4e5883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to  eval/baseline_recommendation_per_user.json\n"
     ]
    }
   ],
   "source": [
    "# Because the baseline doesn't need any training, we build it off of the entire set\n",
    "# We’ll use a standard baseline for ranking latent factor model, which is by always recommending the top most popular places in the testing dataset\n",
    "# “Popular” means aggregation of features from each places’ metadata; number of reviews * average rating per store\n",
    "\n",
    "# Preprocessing the data; get the number of reviews per store in the metadata\n",
    "locations_review_count = defaultdict(int)\n",
    "locations_avg_rating = defaultdict(int)\n",
    "\n",
    "# First get the count of all the reviews for each location\n",
    "for review in reviews:\n",
    "    locations_review_count[review[\"gmap_id\"]] += 1\n",
    "\n",
    "# Get the average rating listed in the metadata\n",
    "for metadata in metadata:\n",
    "    locations_avg_rating[metadata[\"gmap_id\"]] = metadata[\"avg_rating\"]\n",
    "\n",
    "# Then multiply the two collected data and fill in the locations_popularity[gmap_id] = number of reviews * average rating\n",
    "locations_popularity = defaultdict(int)\n",
    "\n",
    "for gmap_id in locations_review_count:\n",
    "    locations_popularity[gmap_id] = locations_review_count[gmap_id] * locations_avg_rating[gmap_id]\n",
    "\n",
    "\n",
    "# Getting the resulting \"most popular\" list that can be used for the baseline\n",
    "# Turn the locations_popularity dictionary to list of tuples that we can sort\n",
    "popularity_list = [(pop, gmap_id) for gmap_id, pop in locations_popularity.items()]\n",
    "\n",
    "# Sort in reverse order so the most popular place is at the top\n",
    "popularity_list.sort(reverse=True)\n",
    "\n",
    "# And then the gmap_id only list\n",
    "popularity_list_id = [gmap_id for _, gmap_id in popularity_list]\n",
    "\n",
    "\n",
    "# Building the dictionary to feed to the evaluation function\n",
    "# recommendation[user_id] = [top k items the model recommend]\n",
    "recommendation = {}\n",
    "\n",
    "# Get each user that has reviewed\n",
    "for review in reviews:\n",
    "    user_id = review[\"user_id\"]\n",
    "\n",
    "    # Recommend the top number of hidden reviews for each user\n",
    "    if user_id not in recommendation:\n",
    "        # Filter the popularity list so that the users' revealed likes isn't included here\n",
    "        filtered_popularity_list = []\n",
    "\n",
    "        for name in popularity_list_id:\n",
    "            if name not in users_revealed_likes[user_id]:\n",
    "                filtered_popularity_list.append(name)\n",
    "\n",
    "            if len(filtered_popularity_list) == TOP_K:\n",
    "                break\n",
    "\n",
    "        recommendation[user_id] = filtered_popularity_list[:TOP_K]\n",
    "\n",
    "# Export to json\n",
    "save_likes(BASELINE_REC_FNAME, recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a4f1e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "36d7ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalFunc(recs_fname, hidden_fname):\n",
    "    recs = load_user_likes(recs_fname)\n",
    "    hidden = load_user_likes(hidden_fname)\n",
    "\n",
    "    hit_scores = {}  \n",
    "    high_hit_scores = {}  \n",
    "\n",
    "    for user_id, hidden_items in hidden.items():\n",
    "        recommended_items = recs[user_id]\n",
    "\n",
    "        # count how many hidden items appear in recommendations\n",
    "        hits = sum(1 for item in hidden_items if item in recommended_items)\n",
    "\n",
    "        # divide by number of hidden items\n",
    "        #hit_rate = hits / len(hidden_items)\n",
    "        \n",
    "        hit_for_this_user = 1 if hits > 0 else 0\n",
    "        \n",
    "        hit_scores[user_id] = hit_for_this_user\n",
    "        if len(hidden_items) < 2:\n",
    "            high_hit_scores[user_id] = hit_for_this_user\n",
    "\n",
    "    # average performance across all users\n",
    "    overall_score = sum(hit_scores.values()) / len(hit_scores)\n",
    "\n",
    "    print(\"Overall Hitrate@k score: \",overall_score)\n",
    "\n",
    "    max_user = max(hit_scores, key=hit_scores.get)\n",
    "    max_score = hit_scores[max_user]\n",
    "\n",
    "    print(\"Highest score: \",max_score)\n",
    "\n",
    "    # score when only considering high number of reviews\n",
    "    overall_high_score = sum(high_hit_scores.values()) / len(high_hit_scores)\n",
    "\n",
    "    print(\"Overall high hit score: \", overall_high_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3cf62038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Iterative Update Model\n",
      "Overall Hitrate@k score:  0.006363479163064153\n",
      "Highest score:  1\n",
      "Overall high hit score:  0.005573714739169044\n",
      "Evaluation for BPR Model\n",
      "Overall Hitrate@k score:  0.08545410686286335\n",
      "Highest score:  1\n",
      "Overall high hit score:  0.08073110285006196\n",
      "Evaluation for Baseline Model\n",
      "Overall Hitrate@k score:  0.03219782120006917\n",
      "Highest score:  1\n",
      "Overall high hit score:  0.03045704460861186\n"
     ]
    }
   ],
   "source": [
    "# Running the evaluations\n",
    "\n",
    "print(\"Evaluation for Iterative Update Model\")\n",
    "evalFunc(ITER_UPDATE_REC_FNAME, HIDDEN_LIKES_DATA_FNAME)\n",
    "\n",
    "print(\"Evaluation for BPR Model\")\n",
    "evalFunc(BPR_REC_FNAME, HIDDEN_LIKES_BPR_DATA_FNAME)\n",
    "\n",
    "print(\"Evaluation for Baseline Model\")\n",
    "evalFunc(BASELINE_REC_FNAME, HIDDEN_LIKES_DATA_FNAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
