{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7031de63-00eb-47bb-bf48-280f645bfde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import loader \n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feece988-a685-45b3-9dba-52d59da7f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_reviews = loader.load_to_dict(root+\"review-Washington_10.json.gz\")\n",
    "# train_metadata = loader.load_to_dict(root+\"meta-Washington.json.gz\")\n",
    "test_reviews = loader.load_to_dict(\"review-Oregon_10.json.gz\")\n",
    "test_metadata = loader.load_to_dict(\"meta-Oregon.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28efac15-a556-4846-bd4c-c25d50ddd35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num dupes:  68767\n",
      "Num dupes removed:  0\n",
      "Saved to  eval/users_likes_full.json\n",
      "Saved to  eval/users_revealed_likes.json\n",
      "Saved to  eval/users_hidden_likes.json\n"
     ]
    }
   ],
   "source": [
    "# Get each users' highly reviewed stores list\n",
    "# users_likes[user_id] = [stores they rated >= 4]\n",
    "users_likes = defaultdict(set)\n",
    "dupe_review_count = 0\n",
    "dupe_removed_count = 0\n",
    "\n",
    "for review in test_reviews:\n",
    "    user_id = review[\"user_id\"]\n",
    "    gmap_id = review[\"gmap_id\"]\n",
    "    rating = review[\"rating\"]\n",
    "\n",
    "    if gmap_id in users_likes[user_id]:\n",
    "        dupe_review_count += 1\n",
    "    \n",
    "    # Use the most recent review, meaning if a user re-reviewed a place and they didn't like it, update our set\n",
    "    if gmap_id in users_likes[user_id] and rating < 4:\n",
    "        users_likes[user_id].remove(gmap_id)\n",
    "        dupe_removed_count += 1\n",
    "\n",
    "    if rating >= 4 and (gmap_id not in users_likes[user_id]):\n",
    "        users_likes[user_id].add(gmap_id)\n",
    "\n",
    "print(\"Num dupes: \", dupe_review_count) \n",
    "print(\"Num dupes removed: \", dupe_removed_count) \n",
    "\n",
    "# Split off the users_likes to revealed and hidden\n",
    "users_revealed_likes = defaultdict(list)\n",
    "users_hidden_likes = defaultdict(list)\n",
    "users_total_likes = defaultdict(list)\n",
    "\n",
    "random.seed(42)\n",
    "for user_id, liked_places in users_likes.items():\n",
    "    # For now let's say 8:2 ratio for revealed vs hidden\n",
    "    # Shuffle before splitting\n",
    "\n",
    "    liked_list = list(liked_places)\n",
    "    num_likes = len(liked_list)\n",
    "    \n",
    "    random.shuffle(liked_list)\n",
    "\n",
    "    # ensures at least 1 review is hidden\n",
    "    min_hidden_count = 1\n",
    "    split_point = max(min_hidden_count, int(0.2 * num_likes))\n",
    "\n",
    "    revealed = liked_list[split_point:]\n",
    "    hidden = liked_list[:split_point]\n",
    "    \n",
    "    if len(hidden) >= min_hidden_count:\n",
    "        users_revealed_likes[user_id] = revealed\n",
    "        users_hidden_likes[user_id] = hidden\n",
    "        users_total_likes[user_id] = liked_list\n",
    "\n",
    "# Save user likes: revealed, hidden, and full\n",
    "loader.save_likes(\"users_likes_full.json\", users_total_likes)\n",
    "loader.save_likes(\"users_revealed_likes.json\", users_revealed_likes)\n",
    "loader.save_likes(\"users_hidden_likes.json\", users_hidden_likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b089c6c2-924b-44dc-ba1c-eec37fc1a596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to  eval/baseline_recommendation_per_user.json\n",
      "Baseline Implementation\n"
     ]
    }
   ],
   "source": [
    "# Because the baseline doesn't need any training, we ignore the train sets and just build it off of the test set\n",
    "# We’ll use a standard baseline for ranking latent factor model, which is by always recommending the top most popular places in the testing dataset\n",
    "# “Popular” means aggregation of features from each places’ metadata; number of reviews * average rating per store\n",
    "\n",
    "# Preprocessing the data; get the number of reviews per store in the metadata\n",
    "locations_review_count = defaultdict(int)\n",
    "locations_avg_rating = defaultdict(int)\n",
    "\n",
    "# First get the count of all the reviews for each location\n",
    "for review in test_reviews:\n",
    "    locations_review_count[review[\"gmap_id\"]] += 1\n",
    "\n",
    "# Get the average rating listed in the metadata\n",
    "for metadata in test_metadata:\n",
    "    locations_avg_rating[metadata[\"gmap_id\"]] = metadata[\"avg_rating\"]\n",
    "\n",
    "# Then multiply the two collected data and fill in the locations_popularity[gmap_id] = number of reviews * average rating\n",
    "locations_popularity = defaultdict(int)\n",
    "\n",
    "for gmap_id in locations_review_count:\n",
    "    locations_popularity[gmap_id] = locations_review_count[gmap_id] * locations_avg_rating[gmap_id]\n",
    "\n",
    "\n",
    "# Getting the resulting \"most popular\" list that can be used for the baseline\n",
    "# Turn the locations_popularity dictionary to list of tuples that we can sort\n",
    "popularity_list = [(pop, gmap_id) for gmap_id, pop in locations_popularity.items()]\n",
    "\n",
    "# Sort in reverse order so the most popular place is at the top\n",
    "popularity_list.sort(reverse=True)\n",
    "\n",
    "# And then the gmap_id only list\n",
    "popularity_list_id = [gmap_id for _, gmap_id in popularity_list]\n",
    "\n",
    "\n",
    "# Building the dictionary to feed to the evaluation function\n",
    "# recommendation[user_id] = [top k items the model recommend]\n",
    "recommendation = {}\n",
    "\n",
    "# Get each user that has reviewed\n",
    "for review in test_reviews:\n",
    "    user_id = review[\"user_id\"]\n",
    "\n",
    "    # Recommend the top number of hidden reviews for each user\n",
    "    k = 30 # 2 * len(users_hidden_likes[user_id])\n",
    "\n",
    "    if user_id not in recommendation:\n",
    "        # Filter the popularity list so that the users' revealed likes isn't included here\n",
    "        filtered_popularity_list = []\n",
    "\n",
    "        for name in popularity_list_id:\n",
    "            if name not in users_revealed_likes[user_id]:\n",
    "                filtered_popularity_list.append(name)\n",
    "\n",
    "            if len(filtered_popularity_list) == k:\n",
    "                break\n",
    "\n",
    "        recommendation[user_id] = filtered_popularity_list[:k]\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open(\"baseline_recommendation_per_user.json\", \"w\") as fp:\n",
    "#     json.dump(recommendation, fp, indent=4)\n",
    "loader.save_likes(\"baseline_recommendation_per_user.json\", recommendation)\n",
    "\n",
    "print(\"Baseline Implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0ad0e69-a732-4b0a-adf8-70fd5e955e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0x54950c57cd36d3cb:0x6f866d66264752ab', '0x549575786b8b269f:0xb3548313bd7fccfd', '0x5495a40b739922e1:0x1386e3022fac1181', '0x5495a752d90af2bd:0xac4da428b0c0c9a7', '0x54950a2eb856b805:0xe7e720b09eddfc26', '0x54ea92b04ed31491:0xf497b5d87639810', '0x5495a0b4338cb23b:0xdf44bd5a7cbcbde4', '0x549618d8d788f7cd:0xe1cbc1f79d7ed701', '0x54eb2c9d759f3191:0xe3b93c57067a899a', '0x54950ee686837673:0x4c238b5a749b4606', '0x54959ad6cca60deb:0xc5a043e2f635f', '0x54950a03b7b42a07:0x60d8820872cc912f', '0x54c11de4265cd325:0xa3a7d53c0aae45d3', '0x5495a2ae617645a7:0x9975eb0f90219342', '0x54950a0764850d75:0xfd20dac4cfa02bff', '0x54950ebce09dcfb9:0xbfe26b0a2d6fc123', '0x54950a72e8b112d1:0xd074694827faf84c', '0x54c5b55eda22e2a9:0x1f87d215776a4838', '0x54bfedda86d4a279:0x3d55c036fa2ccf71', '0x54950a051d703e13:0xfebc36dc49ec79c7', '0x54b8c632c16b82f3:0xc2979d3396b38cf0', '0x54950c04c07d5089:0x5b2f345008809c32', '0x54be1eaaa37312a3:0x6738b4912b8ca4f2', '0x5495a0370172b005:0x22f3cf34eb51d736', '0x5495a40c5458df53:0x2309a594b2d98b3d', '0x5495759c0140408f:0xa25edb2a4606c29e', '0x5495a6e841c06601:0x4006a62af99f8de0', '0x54956ef3a54c58fd:0x207d0a3a371d5709', '0x54950566e51a7037:0xefe15a73ac08f487', '0x54cf7bb81d124cd7:0x2e2cf576e39bfd1']\n"
     ]
    }
   ],
   "source": [
    "print(recommendation[\"116238557567455956213\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
